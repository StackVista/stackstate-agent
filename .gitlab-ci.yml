stages:
  - triggers

# Gitlab CI Process:
#   - Molecule instances spun up won't run for longer than 2 hours and 30 minutes. After the max time, a script will clean those instances to prevent EC2 costs from racking up from zombie instances
#   - Only one instance per branch is allowed. What that means is if you push up another commit, the prepare stage will destroy the ec2 machine from your previous builds. If you get a message that says x-x-x-branch-name-lock, that means you have a prev branch still running and need to kill that branch to release the lock to allow your new branch to continue. This prevents a lot of useless EC2 instances from running and building up costs (We did include interrupt but GitLab seems to be broken on interrupts atm)
#   - If a step in the "Cleanup" stage ran to destroy a molecule machine, or your acceptance step complains about "Unable to reach the ssh machine", then your molecule instance might have been destroyed or cleaned up. To recreate it, rerun the appropriate "Prepare" stage step to spin the machine back up

# Supported Commit Message Functionality:
#   ** Default: Note these do not have to be defined, by default everything will be included except secrets and localinstall which **
#   ** falls on master and tags **

# The following will run a single molecule pipeline and ignore the rest
# this will reduce ec2 costs, possible wait times and clutter
#   - "<commit message> [molecule-compose]"
#   - "<commit message> [molecule-integrations]"
#   - "<commit message> [molecule-secrets]"
#   - "<commit message> [molecule-localinstall]"
#   - "<commit message> [molecule-kubernetes]"
#   - "<commit message> [molecule-swarm]"
#   - "<commit message> [molecule-vms]"

# You can also reduce ec2 costs and clutter by defining the py version you want to build
#   - "<commit message> [py2]"
#   - "<commit message> [py3]"

# This would be ideal to reduce the pipeline build to only what's required
# You can combine tags from the top to stack filters for example:
#   - "<commit message> [py2][molecule-compose]"
#   - "<commit message> [py3][molecule-secrets][molecule-vms]"

# You can also reduce the costs by running no molecule tests
#   - "<commit message> [molecule-none]"

variables: &commonvariables
  # The SRC_PATH is in the GOPATH of the builders which
  # currently is /go
  SRC_PATH: /go/src/github.com/StackVista/stackstate-agent
  # Directory in which we execute the omnibus build.
  # For an unknown reason, it does not go well with
  # a ruby dependency if we build directly into $CI_PROJECT_DIR/.omnibus
  OMNIBUS_BASE_DIR: /.omnibus
  OMNIBUS_BASE_DIR_WIN: c:/omnibus-ruby #\$CI_RUNNER_ID
  # Directory in which we execute the omnibus build for SUSE
  # as we want to separate the RPM built for this distro.
  BCC_VERSION: v0.12.0
  SYSTEM_PROBE_GO_VERSION: 1.13.11
  DATADOG_AGENT_EMBEDDED_PATH: /opt/datadog-agent/embedded
  ARCH: amd64
  VCINSTALLDIR: "C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community"
  MOLECULE_K8S_CLUSTER: eks_test_cluster_1_21
  # This variable represents which one of the gitlab pipelines will contain most of the jobs that's not required for both pipelines to run.
  # IE VMS is a massive jobs and only has to run on either v2 or the v3 pipeline. With this variable you can control on which of the pipelines
  # do jobs like these run on
  PRIMARY_MAJOR_VERSION: '2'
  HELM_CHART_VERSION: 'latest'
  PROCESS_AGENT_TEST_REPO: stackstate-process-agent-test


.agent2_variables: &agent2_variables
  CONDA_ENV: ddpy2
  PYTHON_RUNTIMES: '2'
  MAJOR_VERSION: '2'
  STS_VER: 'v2'
  STS_AWS_RELEASE_BUCKET: stackstate-agent-2
  STS_AWS_TEST_BUCKET: stackstate-agent-2-test
  STS_AWS_RELEASE_BUCKET_YUM: stackstate-agent-2-rpm
  STS_AWS_TEST_BUCKET_YUM: stackstate-agent-2-rpm-test
  STS_AWS_RELEASE_BUCKET_WIN: stackstate-agent-2
  STS_AWS_TEST_BUCKET_WIN: stackstate-agent-2-test
  STS_DOCKER_RELEASE_REPO: stackstate-agent-2
  STS_DOCKER_TEST_REPO: stackstate-agent-2-test
  STS_DOCKER_RELEASE_REPO_TRACE: stackstate-trace-agent
  STS_DOCKER_TEST_REPO_TRACE: stackstate-trace-agent-test
  STS_DOCKER_RELEASE_REPO_CLUSTER: stackstate-cluster-agent
  STS_DOCKER_TEST_REPO_CLUSTER: stackstate-cluster-agent-test
  STS_DOCKER_RELEASE_REPO_SWARM: stackstate-swarm-agent
  STS_DOCKER_TEST_REPO_SWARM: stackstate-swarm-agent-test

.agent3_variables: &agent3_variables
  CONDA_ENV: ddpy3
  PYTHON_RUNTIMES: '3'
  MAJOR_VERSION: '3'
  STS_VER: 'v3'
  STS_AWS_RELEASE_BUCKET: stackstate-agent-3
  STS_AWS_TEST_BUCKET: stackstate-agent-3-test
  STS_AWS_RELEASE_BUCKET_YUM: stackstate-agent-3-rpm
  STS_AWS_TEST_BUCKET_YUM: stackstate-agent-3-rpm-test
  STS_AWS_RELEASE_BUCKET_WIN: stackstate-agent-3
  STS_AWS_TEST_BUCKET_WIN: stackstate-agent-3-test
  STS_DOCKER_RELEASE_REPO: stackstate-agent
  STS_DOCKER_TEST_REPO: stackstate-agent-test
  # we do not build trace-agent and cluster-agent for v2

.always_scheduled_master_and_tags: &always_scheduled_master_and_tags
  - if: $CI_COMMIT_TAG || ($CI_COMMIT_REF_NAME == "master" && $CI_PIPELINE_SOURCE=="schedule")
    when: always

# build Agent package for rpm-arm64
agent_rpm-arm64-a7:
  rules:
    - <<: *if_version_7
  stage: package_build
  needs: ["run_go_tidy_check", "build_system-probe-arm64", "linux_arm64_go_deps"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/rpm_arm64:$DATADOG_AGENT_ARMBUILDIMAGES
  tags: ["runner:docker-arm", "platform:arm64"]
  variables:
    AGENT_MAJOR_VERSION: 7
    PYTHON_RUNTIMES: '3'
    PACKAGE_ARCH: arm64
  before_script:
    - *retrieve_linux_go_deps
    - source /root/.bashrc
    - export RELEASE_VERSION=$RELEASE_VERSION_7
  <<: *agent_build_common_rpm

.iot_agent_build_common_rpm: &iot_agent_build_common_rpm
  rules:
    - <<: *if_version_7
  script:
    - *retrieve_linux_go_deps
    - echo "About to build iot agent for $RELEASE_VERSION_7"
    - echo "Detected host architecture $(uname -m)"
    # $DD_TARGET_ARCH is only set by Arm build images, so assume amd64 if not present
    - echo "Target architecture ${DD_TARGET_ARCH:=amd64}"
    # remove artifacts from previous pipelines that may come from the cache
    - rm -rf $OMNIBUS_PACKAGE_DIR/*
    # Artifacts and cache must live within project directory but we run omnibus in a neutral directory.
    # Thus, we move the artifacts at the end in a gitlab-friendly dir.
    - set +x
    - RPM_GPG_KEY=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.rpm_signing_private_key_e09422b3 --with-decryption --query "Parameter.Value" --out text)
    - printf -- "$RPM_GPG_KEY" | gpg --import --batch
    - export RPM_SIGNING_PASSPHRASE=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.rpm_signing_key_passphrase_e09422b3 --with-decryption --query "Parameter.Value" --out text)
    - set -x
    # Use --skip-deps since the deps are installed by `before_script`.
    - inv -e agent.omnibus-build --iot --log-level debug --release-version "$RELEASE_VERSION_7" --major-version 7 --base-dir $OMNIBUS_BASE_DIR --skip-deps
    - ls $OMNIBUS_BASE_DIR/pkg/
    - mkdir -p $OMNIBUS_PACKAGE_DIR && cp $OMNIBUS_BASE_DIR/pkg/*.{rpm,metadata.json} $OMNIBUS_PACKAGE_DIR
  artifacts:
    expire_in: 2 weeks
    paths:
      - $OMNIBUS_PACKAGE_DIR

iot_agent_rpm-x64:
  stage: package_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/rpm_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:2xlarge" ]
  needs: ["fail_on_non_triggered_tag", "linux_x64_go_deps"]
  <<: *iot_agent_build_common_rpm

iot_agent_rpm-arm64:
  stage: package_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/rpm_arm64:$DATADOG_AGENT_ARMBUILDIMAGES
  tags: ["runner:docker-arm", "platform:arm64"]
  needs: ["fail_on_non_triggered_tag", "linux_arm64_go_deps"]
  <<: *iot_agent_build_common_rpm

iot_agent_rpm-armhf:
  stage: package_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/rpm_armhf:$DATADOG_AGENT_ARMBUILDIMAGES
  # Run with platform:arm64 since no platform:armhf exists and arm64 should be backwards compatible
  tags: ["runner:docker-arm", "platform:arm64"]
  needs: [ "fail_on_non_triggered_tag", "linux_armhf_go_deps"]
  before_script:
    # Ensures uname -m reports armv7l
    - export LD_PRELOAD="/usr/local/lib/libfakearmv7l.so"
  <<: *iot_agent_build_common_rpm

.agent_build_common_suse_rpm: &agent_build_common_suse_rpm
  script:
    - echo "About to build for $RELEASE_VERSION"
    # remove artifacts from previous pipelines that may come from the cache
    - rm -rf $OMNIBUS_PACKAGE_DIR_SUSE/*
    # Artifacts and cache must live within project directory but we run omnibus in a neutral directory.
    # Thus, we move the artifacts at the end in a gitlab-friendly dir.
    - set +x
    - RPM_GPG_KEY=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.rpm_signing_private_key_e09422b3 --with-decryption --query "Parameter.Value" --out text)
    - printf -- "$RPM_GPG_KEY" | gpg --import --batch
    - export RPM_SIGNING_PASSPHRASE=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.rpm_signing_key_passphrase_e09422b3 --with-decryption --query "Parameter.Value" --out text)
    - set -x
    - $S3_CP_CMD $S3_ARTIFACTS_URI/system-probe.${PACKAGE_ARCH} /tmp/system-probe
    - chmod 755 /tmp/system-probe
    - $S3_CP_CMD $S3_ARTIFACTS_URI/libbcc-${PACKAGE_ARCH}.tar.xz /tmp/libbcc.tar.xz
    # use --skip-deps since the deps are installed by `before_script`
    - inv -e agent.omnibus-build --release-version "$RELEASE_VERSION" --major-version "$AGENT_MAJOR_VERSION" --python-runtimes "$PYTHON_RUNTIMES" --base-dir $OMNIBUS_BASE_DIR_SUSE ${USE_S3_CACHING} --skip-deps --system-probe-bin=/tmp/system-probe --libbcc-tarball=/tmp/libbcc.tar.xz
    - find $OMNIBUS_BASE_DIR_SUSE/pkg -type f -name '*.rpm' ! -name '*dbg*.rpm' -print0 | xargs -0 -I '{}' zypper in '{}'
    - find $OMNIBUS_BASE_DIR_SUSE/pkg -type f -name '*dbg*.rpm' -print0 | xargs -0 -I '{}' zypper in '{}'
    - mkdir -p $OMNIBUS_PACKAGE_DIR_SUSE && cp $OMNIBUS_BASE_DIR_SUSE/pkg/*.{rpm,metadata.json} $OMNIBUS_PACKAGE_DIR_SUSE
    # FIXME: skip the installation step until we fix the preinst/postinst scripts in the rpm package
    # to also work with SUSE11
    # - rpm -i $OMNIBUS_PACKAGE_DIR_SUSE/*.rpm
  # TODO: enabling the cache cause builds to be slower and slower on `master`. Re-enable once this is investigated/fixed
  # cache:
  #   # cache per branch
  #   key: $CI_COMMIT_REF_NAME
  #   paths:
  #     - $OMNIBUS_BASE_DIR_SUSE
  artifacts:
    expire_in: 2 weeks
    paths:
      - $OMNIBUS_PACKAGE_DIR_SUSE

# build Agent package for suse-x64
agent_suse-x64-a6:
  rules:
    - <<: *if_version_6
  stage: package_build
  needs: ["run_tests_rpm-x64-py2", "run_tests_rpm-x64-py3", "build_system-probe-x64", "linux_x64_go_deps"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/suse_x64:$DATADOG_AGENT_BUILDERS
  tags: [ "runner:main", "size:2xlarge" ]
  variables:
    AWS_CONTAINER_CREDENTIALS_RELATIVE_URI: /credentials
    AGENT_MAJOR_VERSION: 6
    PYTHON_RUNTIMES: '2,3'
    PACKAGE_ARCH: amd64
  before_script:
    - *retrieve_linux_go_deps
    - export RELEASE_VERSION=$RELEASE_VERSION_6
  <<: *agent_build_common_suse_rpm

# build Agent package for suse-x64
agent_suse-x64-a7:
  rules:
    - <<: *if_version_7
  stage: package_build
  needs: ["run_tests_rpm-x64-py3", "build_system-probe-x64", "linux_x64_go_deps"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/suse_x64:$DATADOG_AGENT_BUILDERS
  tags: [ "runner:main", "size:2xlarge" ]
  variables:
    AWS_CONTAINER_CREDENTIALS_RELATIVE_URI: /credentials
    AGENT_MAJOR_VERSION: 7
    PYTHON_RUNTIMES: '3'
    PACKAGE_ARCH: amd64
  before_script:
    - *retrieve_linux_go_deps
    - export RELEASE_VERSION=$RELEASE_VERSION_7
  <<: *agent_build_common_suse_rpm

iot_agent_suse-x64:
  rules:
    - <<: *if_version_7
  stage: package_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/suse_x64:$DATADOG_AGENT_BUILDERS
  tags: [ "runner:main", "size:2xlarge" ]
  needs: ["fail_on_non_triggered_tag", "linux_x64_go_deps"]
  before_script:
    - *retrieve_linux_go_deps
  script:
    - echo "About to build iot agent for $RELEASE_VERSION_7"
    - echo "Detected host architecture $(uname -m)"
    # $DD_TARGET_ARCH is only set by Arm build images, so assume amd64 if not present
    - echo "Target architecture ${DD_TARGET_ARCH:=amd64}"
    # remove artifacts from previous pipelines that may come from the cache
    - rm -rf $OMNIBUS_PACKAGE_DIR_SUSE/*
    # Artifacts and cache must live within project directory but we run omnibus in a neutral directory.
    # Thus, we move the artifacts at the end in a gitlab-friendly dir.
    - set +x
    - RPM_GPG_KEY=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.rpm_signing_private_key_e09422b3 --with-decryption --query "Parameter.Value" --out text)
    - printf -- "$RPM_GPG_KEY" | gpg --import --batch
    - export RPM_SIGNING_PASSPHRASE=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.rpm_signing_key_passphrase_e09422b3 --with-decryption --query "Parameter.Value" --out text)
    - set -x
    # Use --skip-deps since the deps are installed by `before_script`.
    - inv -e agent.omnibus-build --iot --log-level debug --release-version "$RELEASE_VERSION_7" --major-version 7 --base-dir $OMNIBUS_BASE_DIR --skip-deps
    - ls $OMNIBUS_BASE_DIR/pkg/
    - mkdir -p $OMNIBUS_PACKAGE_DIR_SUSE && cp $OMNIBUS_BASE_DIR/pkg/*.{rpm,metadata.json} $OMNIBUS_PACKAGE_DIR_SUSE
  artifacts:
    expire_in: 2 weeks
    paths:
      - $OMNIBUS_PACKAGE_DIR_SUSE

# cloudfoundry iot build/windows
windows_zip_agent_binaries_x64-a7:
  rules:
    - <<: *if_version_7
  stage: package_build
  tags: ["runner:windows-docker", "windowsversion:1809"]
  needs: ["run_go_tidy_check"]
  variables:
    ARCH: "x64"
    AGENT_MAJOR_VERSION: 7
    OMNIBUS_TARGET: agent_binaries
  before_script:
    - set RELEASE_VERSION $RELEASE_VERSION_7
  script:
    - if (Test-Path .omnibus) { remove-item -recurse -force .omnibus }
    - if (Test-Path build-out) { remove-item -recurse -force build-out }
    - mkdir .omnibus\pkg
    - docker run --rm -m 4096M -v "$(Get-Location):c:\mnt" -e OMNIBUS_TARGET=${OMNIBUS_TARGET} -e WINDOWS_BUILDER=true -e RELEASE_VERSION="$RELEASE_VERSION" -e MAJOR_VERSION="$AGENT_MAJOR_VERSION" -e PY_RUNTIMES="$PYTHON_RUNTIMES" -e AWS_NETWORKING=true -e SIGN_WINDOWS=true 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/windows_1809_${ARCH}:${Env:DATADOG_AGENT_WINBUILDIMAGES} c:\mnt\tasks\winbuildscripts\buildwin.bat
    - copy build-out\*.zip .omnibus\pkg
  artifacts:
    expire_in: 2 weeks
    paths:
      - .omnibus/pkg

##
## windows dockerized builds
##

.windows_msi_base:
  stage: package_build
  needs: ["run_go_tidy_check"]
  tags: ["runner:windows-docker", "windowsversion:1809"]
  # Unavailable on gitlab < 12.3
  # timeout: 2h 00m
  script:
    - if (Test-Path .omnibus) { remove-item -recurse -force .omnibus }
    - if (Test-Path build-out) { remove-item -recurse -force build-out }
    - mkdir .omnibus\pkg
    - docker run --rm -m 4096M -v "$(Get-Location):c:\mnt" -e CI_JOB_ID=${CI_JOB_ID} -e OMNIBUS_TARGET=${OMNIBUS_TARGET} -e WINDOWS_BUILDER=true -e RELEASE_VERSION="$RELEASE_VERSION" -e MAJOR_VERSION="$AGENT_MAJOR_VERSION" -e PY_RUNTIMES="$PYTHON_RUNTIMES" -e AWS_NETWORKING=true -e SIGN_WINDOWS=true -e TARGET_ARCH="$ARCH" 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/windows_1809_${ARCH}:${Env:DATADOG_AGENT_WINBUILDIMAGES} c:\mnt\tasks\winbuildscripts\buildwin.bat
    - copy build-out\${CI_JOB_ID}\*.msi .omnibus\pkg
    - if (Test-Path build-out\${CI_JOB_ID}\*.zip) { copy build-out\${CI_JOB_ID}\*.zip .omnibus\pkg }
    - remove-item -recurse -force build-out\${CI_JOB_ID}
    - get-childitem build-out
    - get-childitem .omnibus\pkg
  artifacts:
    expire_in: 2 weeks
    paths:
      - .omnibus/pkg

.windows_main_agent_base:
  extends: .windows_msi_base
  variables:
    OMNIBUS_TARGET: main

windows_msi_x64-a7:
  rules:
    - <<: *if_version_7
  extends: .windows_main_agent_base
  variables:
    ARCH: "x64"
    AGENT_MAJOR_VERSION: 7
    PYTHON_RUNTIMES: '3'
  before_script:
    - set RELEASE_VERSION $RELEASE_VERSION_7

windows_msi_x86-a7:
  rules:
    - <<: *if_not_version_7
      when: never
    - <<: *if_triggered
      when: never
    - when: on_success
  extends: .windows_main_agent_base
  allow_failure: true
  variables:
    ARCH: "x86"
    AGENT_MAJOR_VERSION: 7
    PYTHON_RUNTIMES: '3'
  before_script:
    - set RELEASE_VERSION $RELEASE_VERSION_7

windows_msi_x64-a6:
  rules:
    - <<: *if_version_6
  extends: .windows_main_agent_base
  variables:
    ARCH: "x64"
    AGENT_MAJOR_VERSION: 6
    PYTHON_RUNTIMES: '2,3'
  before_script:
    - set RELEASE_VERSION $RELEASE_VERSION_6

windows_msi_x86-a6:
  rules:
    - <<: *if_not_version_6
      when: never
    - <<: *if_triggered
      when: never
    - when: on_success
  extends: .windows_main_agent_base
  allow_failure: true
  variables:
    ARCH: "x86"
    AGENT_MAJOR_VERSION: 6
    PYTHON_RUNTIMES: '2,3'
  before_script:
    - set RELEASE_VERSION $RELEASE_VERSION_6

# build dogstatsd package for Windows
windows_dsd_msi_x64-a7:
  rules:
    - <<: *if_version_7
  extends: .windows_msi_base
  variables:
    ARCH: "x64"
    PYTHON_RUNTIMES: ""
    AGENT_MAJOR_VERSION: '7'
    OMNIBUS_TARGET: dogstatsd
  before_script:
    - set RELEASE_VERSION $RELEASE_VERSION_7

# The online version fetches the package from S3 so
# it is created only when the package is pushed
windows_choco_online_7_x64:
  rules:
    - <<: *if_triggered_on_tag_7
  stage: choco_build
  tags: ["runner:windows-docker", "windowsversion:1809"]
  needs: ["deploy_staging_windows_tags-a7"]
  variables:
    ARCH: "x64"
  script:
    - $ErrorActionPreference = "Stop"
    - if (Test-Path .omnibus) { remove-item -recurse -force .omnibus }
    - if (Test-Path build-out) { remove-item -recurse -force build-out }
    - mkdir .omnibus\pkg
    - docker run --rm -v "$(Get-Location):c:\mnt" 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/windows_1809_${ARCH}:${Env:DATADOG_AGENT_WINBUILDERS} c:\mnt\tasks\winbuildscripts\chocopack.bat online
    - If ($lastExitCode -ne "0") { throw "Previous command returned $lastExitCode" }
    - copy build-out\*.nupkg .omnibus\pkg
  artifacts:
    expire_in: 2 weeks
    paths:
      - .omnibus/pkg

windows_choco_offline_7_x64:
  rules:
    - <<: *if_version_7
      when: manual
      allow_failure: true
  stage: image_build
  tags: ["runner:windows-docker", "windowsversion:1809"]
  needs: ["windows_msi_x64-a7"]
  variables:
    ARCH: "x64"
  script:
    - $ErrorActionPreference = "Stop"
    - Get-ChildItem .omnibus\pkg
    - copy .omnibus\pkg\*.msi .\chocolatey\tools-offline\
    - docker run --rm -v "$(Get-Location):c:\mnt" 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/windows_1809_${ARCH}:${Env:DATADOG_AGENT_WINBUILDERS} c:\mnt\tasks\winbuildscripts\chocopack.bat offline
    - If ($lastExitCode -ne "0") { throw "Previous command returned $lastExitCode" }
    - copy build-out\*.nupkg .omnibus\pkg
  artifacts:
    expire_in: 2 weeks
    paths:
      - .omnibus/pkg

publish_choco_7_x64:
  rules:
    - <<: *if_triggered_on_tag_7
      when: manual
      allow_failure: true
  stage: choco_deploy
  tags: ["runner:windows-docker", "windowsversion:1809"]
  needs: ["windows_choco_online_7_x64"]
  variables:
    ARCH: "x64"
  before_script:
    - $chocolateyApiKey = (aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.chocolatey_api_key --with-decryption --query "Parameter.Value" --out text)
  script:
    - $ErrorActionPreference = "Stop"
    - Get-ChildItem .omnibus\pkg
    - if (Test-Path nupkg) { remove-item -recurse -force nupkg }
    - mkdir nupkg
    - copy .omnibus\pkg\*.nupkg nupkg\
    - Get-ChildItem nupkg
    - docker run --rm -v "$(Get-Location):c:\mnt" -e CHOCOLATEY_API_KEY=${chocolateyApiKey} 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/windows_1809_${ARCH}:${Env:DATADOG_AGENT_WINBUILDERS} c:\mnt\tasks\winbuildscripts\chocopush.bat
    - If ($lastExitCode -ne "0") { throw "Previous command returned $lastExitCode" }

# build Agent package for android
agent_android_apk:
  rules:
    - <<: *if_not_version_7
      when: never
    - <<: *if_triggered
      when: never
    - when: on_success
  stage: package_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/android_builder:$DATADOG_AGENT_BUILDERS
  tags: [ "runner:main", "size:large" ]
  variables:
    AWS_CONTAINER_CREDENTIALS_RELATIVE_URI: /credentials
  before_script:
    - echo running android before_script
    - cd $SRC_PATH
    - python3 -m pip install -r requirements.txt
    - inv -e deps --android --dep-vendor-only
    # Some Android license has changed, we have to accept the new version.
    # But on top of that, there is a bug in sdkmanager not updating correctly
    # the existing license, so, we have to manually accept the new license.
    # https://issuetracker.google.com/issues/123054726
    # The real fix will be to change the builders
    - echo "24333f8a63b6825ea9c5514f83c2829b004d1fee" > "$ANDROID_HOME/licenses/android-sdk-license"
  script:
    # remove artifacts from previous pipelines that may come from the cache
    - rm -rf $OMNIBUS_PACKAGE_DIR/*
    # for now do the steps manually.  Should eventually move this to an invoke
    # task
    - inv -e android.build --major-version 7
    - mkdir -p $OMNIBUS_PACKAGE_DIR
    - cp ./bin/agent/ddagent-*-unsigned.apk $OMNIBUS_PACKAGE_DIR
  artifacts:
    expire_in: 2 weeks
    paths:
      - $OMNIBUS_PACKAGE_DIR

# build Dogstatsd package for deb-x64
dogstatsd_deb-x64:
  rules:
    - <<: *if_version_7
  stage: package_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:large" ]
  needs: ["build_dogstatsd-deb_x64", "linux_x64_go_deps"]
  variables:
    AWS_CONTAINER_CREDENTIALS_RELATIVE_URI: /credentials
  before_script:
    - *retrieve_linux_go_deps
    - source /root/.bashrc && conda activate ddpy3
  script:
    # remove artifacts from previous pipelines that may come from the cache
    - rm -rf $OMNIBUS_PACKAGE_DIR/*
    # Artifacts and cache must live within project directory but we run omnibus in a neutral directory.
    # Thus, we move the artifacts at the end in a gitlab-friendly dir.
    # Use --skip-deps since the deps are installed by `before_script`.
    - inv -e dogstatsd.omnibus-build --release-version "$RELEASE_VERSION_7" --major-version 7 --base-dir $OMNIBUS_BASE_DIR ${USE_S3_CACHING} --skip-deps
    - find $OMNIBUS_BASE_DIR/pkg -name "datadog-dogstatsd*_amd64.deb" -exec dpkg -c {} \;
    - $S3_CP_CMD $OMNIBUS_BASE_DIR/pkg/datadog-dogstatsd*_amd64.deb $S3_ARTIFACTS_URI/datadog-dogstatsd_amd64.deb
    - mkdir -p $OMNIBUS_PACKAGE_DIR && cp $OMNIBUS_BASE_DIR/pkg/datadog-dogstatsd*_amd64.deb{,.metadata.json} $OMNIBUS_PACKAGE_DIR
  # TODO: enabling the cache cause builds to be slower and slower on `master`. Re-enable once this is investigated/fixed
  # cache:
  #   # cache per branch
  #   key: $CI_COMMIT_REF_NAME
  #   paths:
  #     - $OMNIBUS_BASE_DIR
  artifacts:
    expire_in: 2 weeks
    paths:
      - $OMNIBUS_PACKAGE_DIR

# build Dogstatsd package for rpm-x64
dogstatsd_rpm-x64:
  rules:
    - <<: *if_version_7
  stage: package_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/rpm_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:large" ]
  needs: ["build_dogstatsd-deb_x64", "linux_x64_go_deps"]
  variables:
    AWS_CONTAINER_CREDENTIALS_RELATIVE_URI: /credentials
  before_script:
    - *retrieve_linux_go_deps
    - source /root/.bashrc && conda activate ddpy3
  script:
    # remove artifacts from previous pipelines that may come from the cache
    - rm -rf $OMNIBUS_PACKAGE_DIR/*
    # Artifacts and cache must live within project directory but we run omnibus
    # from the GOPATH (see above). We then call `invoke` passing --base-dir,
    # pointing to a gitlab-friendly location.
    - set +x
    - RPM_GPG_KEY=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.rpm_signing_private_key --with-decryption --query "Parameter.Value" --out text)
    - printf -- "$RPM_GPG_KEY" | gpg --import --batch
    - export RPM_SIGNING_PASSPHRASE=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.rpm_signing_key_passphrase --with-decryption --query "Parameter.Value" --out text)
    - set -x
    # Use --skip-deps since the deps are installed by `before_script`.
    - inv -e dogstatsd.omnibus-build --release-version "$RELEASE_VERSION_7" --major-version 7 --base-dir $OMNIBUS_BASE_DIR ${USE_S3_CACHING} --skip-deps
    - find $OMNIBUS_BASE_DIR/pkg -type f -name '*.rpm' -print0 | sort -z | xargs -0 -I '{}' rpm -i '{}'
    - mkdir -p $OMNIBUS_PACKAGE_DIR && cp $OMNIBUS_BASE_DIR/pkg/*.{rpm,metadata.json} $OMNIBUS_PACKAGE_DIR
  # TODO: enabling the cache cause builds to be slower and slower on `master`. Re-enable once this is investigated/fixed
  # cache:
  #   # cache per branch
  #   key: $CI_COMMIT_REF_NAME
  #   paths:
  #     - $OMNIBUS_BASE_DIR
  artifacts:
    expire_in: 2 weeks
    paths:
      - $OMNIBUS_PACKAGE_DIR


# build Dogstatsd package for rpm-x64
dogstatsd_suse-x64:
  rules:
    - <<: *if_version_7
  stage: package_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/suse_x64:$DATADOG_AGENT_BUILDERS
  tags: [ "runner:main", "size:large" ]
  needs: ["build_dogstatsd-deb_x64", "linux_x64_go_deps"]
  variables:
    AWS_CONTAINER_CREDENTIALS_RELATIVE_URI: /credentials
  before_script:
    - *retrieve_linux_go_deps
  script:
    # remove artifacts from previous pipelines that may come from the cache
    - rm -rf $OMNIBUS_PACKAGE_DIR_SUSE/*
    # Artifacts and cache must live within project directory but we run omnibus
    # from the GOPATH (see above). We then call `invoke` passing --base-dir,
    # pointing to a gitlab-friendly location.
    - set +x
    - RPM_GPG_KEY=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.rpm_signing_private_key --with-decryption --query "Parameter.Value" --out text)
    - printf -- "$RPM_GPG_KEY" | gpg --import --batch
    - export RPM_SIGNING_PASSPHRASE=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.rpm_signing_key_passphrase --with-decryption --query "Parameter.Value" --out text)
    - set -x
    # Use --skip-deps since the deps are installed by `before_script`.
    - inv -e dogstatsd.omnibus-build --release-version "$RELEASE_VERSION_7" --major-version 7 --base-dir $OMNIBUS_BASE_DIR_SUSE ${USE_S3_CACHING} --skip-deps
    - find $OMNIBUS_BASE_DIR_SUSE/pkg -type f -name '*.rpm' -print0 | sort -z | xargs -0 -I '{}' rpm -i '{}'
    - mkdir -p $OMNIBUS_PACKAGE_DIR_SUSE && cp $OMNIBUS_BASE_DIR_SUSE/pkg/*.{rpm,metadata.json} $OMNIBUS_PACKAGE_DIR_SUSE
  # TODO: enabling the cache cause builds to be slower and slower on `master`. Re-enable once this is investigated/fixed
  # cache:
  #   # cache per branch
  #   key: $CI_COMMIT_REF_NAME
  #   paths:
  #     - $OMNIBUS_BASE_DIR_SUSE
  artifacts:
    expire_in: 2 weeks
    paths:
      - $OMNIBUS_PACKAGE_DIR_SUSE

# deploy debian packages to apt staging repo
deploy_deb_testing-a6:
  rules:
    - <<: *if_not_version_6
      when: never
    - <<: *if_test_kitchen_triggered
  stage: testkitchen_deploy
  needs: ["agent_deb-x64-a6"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/gitlab_agent_deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  tags: [ "runner:main", "size:large" ]
  variables:
    DD_PIPELINE_ID: $CI_PIPELINE_ID-a6
  script:
    - set +x # make sure we don't output the creds to the build log

    - APT_SIGNING_KEY_ID=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_key_id --with-decryption --query "Parameter.Value" --out text)
    - APT_SIGNING_PRIVATE_KEY_PART1=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_private_key_part1 --with-decryption --query "Parameter.Value" --out text)
    - APT_SIGNING_PRIVATE_KEY_PART2=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_private_key_part2 --with-decryption --query "Parameter.Value" --out text)
    - APT_SIGNING_KEY_PASSPHRASE=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_key_passphrase --with-decryption --query "Parameter.Value" --out text)

    - echo "$APT_SIGNING_KEY_ID"
    - printf -- "$APT_SIGNING_PRIVATE_KEY_PART1\n$APT_SIGNING_PRIVATE_KEY_PART2\n" | gpg --import --batch

    - echo "$APT_SIGNING_KEY_PASSPHRASE" | deb-s3 upload -c "pipeline-$DD_PIPELINE_ID" -m 6 -b $DEB_TESTING_S3_BUCKET -a amd64 --sign=$APT_SIGNING_KEY_ID --gpg_options="--passphrase-fd 0 --batch --digest-algo SHA512" --preserve_versions --visibility public $OMNIBUS_PACKAGE_DIR/datadog-*_6*amd64.deb
    - echo "$APT_SIGNING_KEY_PASSPHRASE" | deb-s3 upload -c "pipeline-$DD_PIPELINE_ID" -m 6 -b $DEB_TESTING_S3_BUCKET -a x86_64 --sign=$APT_SIGNING_KEY_ID --gpg_options="--passphrase-fd 0 --batch --digest-algo SHA512" --preserve_versions --visibility public $OMNIBUS_PACKAGE_DIR/datadog-*_6*amd64.deb

deploy_deb_testing-a7:
  rules:
    - <<: *if_not_version_7
      when: never
    - <<: *if_test_kitchen_triggered
  stage: testkitchen_deploy
  needs: ["agent_deb-x64-a7", "iot_agent_deb-x64", "dogstatsd_deb-x64"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/gitlab_agent_deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  tags: [ "runner:main", "size:large" ]
  variables:
    DD_PIPELINE_ID: $CI_PIPELINE_ID-a7
  script:
    - set +x # make sure we don't output the creds to the build log

    - APT_SIGNING_KEY_ID=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_key_id --with-decryption --query "Parameter.Value" --out text)
    - APT_SIGNING_PRIVATE_KEY_PART1=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_private_key_part1 --with-decryption --query "Parameter.Value" --out text)
    - APT_SIGNING_PRIVATE_KEY_PART2=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_private_key_part2 --with-decryption --query "Parameter.Value" --out text)
    - APT_SIGNING_KEY_PASSPHRASE=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_key_passphrase --with-decryption --query "Parameter.Value" --out text)

    - echo "$APT_SIGNING_KEY_ID"
    - printf -- "$APT_SIGNING_PRIVATE_KEY_PART1\n$APT_SIGNING_PRIVATE_KEY_PART2\n" | gpg --import --batch

    - echo "$APT_SIGNING_KEY_PASSPHRASE" | deb-s3 upload -c "pipeline-$DD_PIPELINE_ID" -m 7 -b $DEB_TESTING_S3_BUCKET -a amd64 --sign=$APT_SIGNING_KEY_ID --gpg_options="--passphrase-fd 0 --batch --digest-algo SHA512" --preserve_versions --visibility public $OMNIBUS_PACKAGE_DIR/datadog-*_7*amd64.deb
    - echo "$APT_SIGNING_KEY_PASSPHRASE" | deb-s3 upload -c "pipeline-$DD_PIPELINE_ID" -m 7 -b $DEB_TESTING_S3_BUCKET -a x86_64 --sign=$APT_SIGNING_KEY_ID --gpg_options="--passphrase-fd 0 --batch --digest-algo SHA512" --preserve_versions --visibility public $OMNIBUS_PACKAGE_DIR/datadog-*_7*amd64.deb

# deploy rpm packages to yum staging repo
deploy_rpm_testing-a6:
  rules:
    - <<: *if_not_version_6
      when: never
    - <<: *if_test_kitchen_triggered
  stage: testkitchen_deploy
  needs: ["agent_rpm-x64-a6"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/gitlab_agent_deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  tags: [ "runner:main", "size:large" ]
  variables:
    DD_PIPELINE_ID: $CI_PIPELINE_ID-a6
  script:
    - rpm-s3 --verbose --visibility public-read -c "https://s3.amazonaws.com" -b $RPM_TESTING_S3_BUCKET -p "pipeline-$DD_PIPELINE_ID/6/x86_64/" $OMNIBUS_PACKAGE_DIR/datadog-*-6.*x86_64.rpm

deploy_rpm_testing-a7:
  rules:
    - <<: *if_not_version_7
      when: never
    - <<: *if_test_kitchen_triggered
  stage: testkitchen_deploy
  needs: ["agent_rpm-x64-a7", "iot_agent_rpm-x64", "dogstatsd_rpm-x64"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/gitlab_agent_deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  tags: [ "runner:main", "size:large" ]
  variables:
    DD_PIPELINE_ID: $CI_PIPELINE_ID-a7
  script:
    - rpm-s3 --verbose --visibility public-read -c "https://s3.amazonaws.com" -b $RPM_TESTING_S3_BUCKET -p "pipeline-$DD_PIPELINE_ID/7/x86_64/" $OMNIBUS_PACKAGE_DIR/datadog-*-7.*x86_64.rpm

# deploy rpm packages to yum staging repo
deploy_suse_rpm_testing-a6:
  rules:
    - <<: *if_not_version_6
      when: never
    - <<: *if_test_kitchen_triggered
  stage: testkitchen_deploy
  needs: ["agent_suse-x64-a6"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/gitlab_agent_deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR_SUSE
  tags: [ "runner:main", "size:large" ]
  variables:
    DD_PIPELINE_ID: $CI_PIPELINE_ID-a6
  script:
    - rpm-s3 --verbose --visibility public-read -c "https://s3.amazonaws.com" -b $RPM_TESTING_S3_BUCKET -p "suse/pipeline-$DD_PIPELINE_ID/6/x86_64/" $OMNIBUS_PACKAGE_DIR_SUSE/datadog-*-6.*x86_64.rpm

deploy_suse_rpm_testing-a7:
  rules:
    - <<: *if_not_version_7
      when: never
    - <<: *if_test_kitchen_triggered
  stage: testkitchen_deploy
  needs: ["agent_suse-x64-a7", "iot_agent_suse-x64", "dogstatsd_suse-x64"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/gitlab_agent_deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR_SUSE
  tags: [ "runner:main", "size:large" ]
  variables:
    DD_PIPELINE_ID: $CI_PIPELINE_ID-a7
  script:
    - rpm-s3 --verbose --visibility public-read -c "https://s3.amazonaws.com" -b $RPM_TESTING_S3_BUCKET -p "suse/pipeline-$DD_PIPELINE_ID/7/x86_64/" $OMNIBUS_PACKAGE_DIR_SUSE/datadog-*-7.*x86_64.rpm

#.other_files_rule: &other_files_rule
#  # Check if any files (not MD) changed
#  # Glob syntax that checks for changes in all files except files that end with .md extension.
#  # (Glob syntax tester: https://toools.cloud/miscellaneous/glob-tester)
#  - changes:
#      - "**/{.*,!(*.md)}"
#    # If any non-MD files changed, always run the pipeline.
#    when: always

# What happens if I updated CHANGELOG.md and some python file?
.md_only_rule: &md_only_rule
  # Check if any MD files changed
  # Glob syntax that checks for changes in files ending with .md extension.
  # (Glob syntax tester: https://toools.cloud/miscellaneous/glob-tester)
  - changes:
      - "**/*.markdown"
      - "**/*.md"
      - "**/*.mdown"
    # If any MD files changed, don't run the pipeline.
    when: manual
    # Allow failure must be true, else manual pipelines can never be successful without running the manual jobs.
    allow_failure: true

.rules:
  - &exclude_on_cluster_agent
    if: $CI_COMMIT_MESSAGE =~ /\[cluster-agent]/
    when: never
  - &include_on_cluster_agent
    if: $CI_COMMIT_MESSAGE =~ /\[cluster-agent]/
    when: on_success
  - &exclude_on_tag_v2
    if: $CI_COMMIT_TAG =~ /2\..*/
    when: never
  - &exclude_on_tag_v3
    if: $CI_COMMIT_TAG =~ /3\..*/
    when: never

agent2:
  stage: triggers
  variables:
    <<: *commonvariables
    <<: *agent2_variables
  trigger:
    include: .gitlab-ci-agent.yml
    strategy: depend
  rules:
    - <<: *exclude_on_cluster_agent
    # exclude this pipeline if we're running a v3 tag pipeline
    - <<: *exclude_on_tag_v3
    - *always_scheduled_master_and_tags
    - if: $CI_COMMIT_MESSAGE =~ /\[py3]/
      when: never
    - *other_files_rule
    - *md_only_rule
    - if: $CI_MERGE_REQUEST_IID
    - if: $CI_OPEN_MERGE_REQUESTS
      when: never
    - if: $CI_COMMIT_BRANCH

# if MD only change, the only pipelines we want to run are scheduled masters and tags.

agent3:
 stage: triggers
 variables:
   <<: *commonvariables
   <<: *agent3_variables
 trigger:
   include: .gitlab-ci-agent.yml
   strategy: depend
 rules:
   - <<: *exclude_on_cluster_agent
   # exclude this pipeline if we're running a v2 tag pipeline
   - <<: *exclude_on_tag_v2
   - *always_scheduled_master_and_tags
   - if: $CI_COMMIT_MESSAGE =~ /\[py2]/
     when: never
   - *other_files_rule
   - *md_only_rule
   - if: $CI_MERGE_REQUEST_IID
   - if: $CI_OPEN_MERGE_REQUESTS
     when: never
   - if: $CI_COMMIT_BRANCH

cluster_agent:
  stage: triggers
  variables:
    <<: *commonvariables
    <<: *agent3_variables
  trigger:
    include: .gitlab-ci-cluster-agent.yml
    strategy: depend
  rules:
    - <<: *include_on_cluster_agent
    - when: never

build_beest_runners:
  stage: triggers
  trigger:
    include: .gitlab-ci-builders.yml
    strategy: depend
  rules:
    - if: $CI_MERGE_REQUEST_IID
    - if: $CI_OPEN_MERGE_REQUESTS
      when: never
    - if: $CI_COMMIT_BRANCH

build_agent_runners:
  stage: triggers
  variables:
    <<: *commonvariables
  trigger:
    include: .gitlab-ci-build-runners.yml
    strategy: depend
  rules:
    - if: $CI_MERGE_REQUEST_IID
    - if: $CI_OPEN_MERGE_REQUESTS
      when: never
    - if: $CI_COMMIT_BRANCH
